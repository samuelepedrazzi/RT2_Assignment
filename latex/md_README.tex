\hypertarget{md_README_autotoc_md1}{}\doxysection{Robot simulator using R\+O\+S, Rviz and Gazebo.}\label{md_README_autotoc_md1}
\DoxyHorRuler{0}
\hypertarget{md_README_autotoc_md3}{}\doxysubsection{Introduction $<$img src= \char`\"{}https\+://media2.\+giphy.\+com/media/f\+Lsd17\+I\+O7\+H\+T\+C\+R85b\+D\+Y/giphy.\+gif?cid=ecf05e47y9qetlendf7s1str4q1hzuzdr4ykg086vprnnccc\&rid=giphy.\+gif\&ct=s\char`\"{} width=100 height=60$>$}\label{md_README_autotoc_md3}
$>$This is a Gazebo and Rviz-\/based R\+OS Robotics Simulator. The goal of this project is to build three mobility modes that the user could choose from to allow the robot to explore an unknown but constrained territory inside the simulation. On a user-\/interface terminal window, the user can pick the robot\textquotesingle{}s desired behavior; the modalities include\+:


\begin{DoxyItemize}
\item {\bfseries{1 -\/ Autonomous Drive}}\+: The user can select a goal position for the robot, and it will reach there on its own.
\item {\bfseries{2 -\/ Free Drive}}\+: The user can use the keyboard to drive the robot in the environment.
\item {\bfseries{3 -\/ Driver Assistant}}\+: The operator can direct the robot\textquotesingle{}s movement with the keyboard, but an collision avoidance algorithm will keep the robot from crashing with walls.
\end{DoxyItemize}\hypertarget{md_README_autotoc_md4}{}\doxysubsection{Installing and Running $<$img src=\char`\"{}https\+://media0.\+giphy.\+com/media/\+Xq\+Y\+Kfpj\+B\+L2bj\+Uc\+W\+V\+Q\+D/200w.\+webp?cid=ecf05e47f0avfktds1q4ksjx91r0uw1m2unss4u1btdrzy12\&rid=200w.\+webp\&ct=s\char`\"{} width=\char`\"{}50\char`\"{}$>$$<$/h2$>$}\label{md_README_autotoc_md4}
This simulator is built on the \href{http://wiki.ros.org}{\texttt{ {\bfseries{R\+OS}}}} ({\bfseries{Robot-\/\+Operating-\/\+Systems}}) platform, specifically the N\+O\+E\+T\+IC version.

For the specific project the program requires the installation of the following packages and tools before it can begin\+:


\begin{DoxyItemize}
\item \href{https://github.com/CarmineD8/slam_gmapping}{\texttt{ Slam Gmapping package}}
\end{DoxyItemize}

which can be installed with the bash command\+:


\begin{DoxyCode}{0}
\DoxyCodeLine{\$ git clone https://github.com/CarmineD8/slam\_gmapping.git}
\end{DoxyCode}



\begin{DoxyItemize}
\item xterm
\end{DoxyItemize}

Easy to install with\+:


\begin{DoxyCode}{0}
\DoxyCodeLine{\$ sudo apt-\/get install -\/y xterm}
\end{DoxyCode}



\begin{DoxyItemize}
\item Ros navigation stack
\end{DoxyItemize}

To Install it\+:


\begin{DoxyCode}{0}
\DoxyCodeLine{\$ sudo apt-\/get install ros-\/<ros\_distro>-\/navigation}
\end{DoxyCode}


Before running the simulation, first you have to run R\+OS (using {\ttfamily \$ roscore \&} and {\ttfamily \$ catkin\+\_\+make} ), then the simulation begins when the user has all of the required packages and runs a .launch file called\+:

{\bfseries{Assignment3\+\_\+\+R\+T1.\+launch}}


\begin{DoxyCode}{0}
\DoxyCodeLine{<?xml version="1.0"?>}
\DoxyCodeLine{}
\DoxyCodeLine{<launch>}
\DoxyCodeLine{  <include file="\$(find Assignment3\_RT1)/launch/simulation\_gmapping.launch"/>}
\DoxyCodeLine{  <include file="\$(find Assignment3\_RT1)/launch/move\_base.launch"/>}
\DoxyCodeLine{ }
\DoxyCodeLine{ <!-\/-\/ Run the UI node -\/-\/>}
\DoxyCodeLine{  <node pkg="Assignment3\_RT1" type="UI" respawn="false" name="UI" output="screen" launch-\/prefix="xterm -\/e" required="true"/>}
\DoxyCodeLine{ }
\DoxyCodeLine{</launch>}
\end{DoxyCode}
\hypertarget{md_README_autotoc_md5}{}\doxysubsection{Environment and mapping}\label{md_README_autotoc_md5}
Rviz (a 3D visualizer for the Robot Operating System (R\+OS) framework) and Gazebo (an open-\/source 3D Robotics simulator) appear on the screen as soon as the simulator starts\+: Thanks to its sensors, the robot can see what\textquotesingle{}s going on in the world around it.

R\+OS creates the environment described in the {\bfseries{world}} folder\textquotesingle{}s file {\ttfamily house.\+world.}

The robot moves in the ambience in the figure (Gazebo view)\+:



The robot knows only the portion of the surroundings that its sensors allow it to detect from its starting point because it does not know all of the map\textquotesingle{}s boundaries.

The robot\textquotesingle{}s map knowledge grows as it moves around the map. The robot\textquotesingle{}s known surroundings is graphed and updated at each time instant on Rviz.

\tabulinesep=1mm
\begin{longtabu}spread 0pt [c]{*{2}{|X[-1]}|}
\hline
\PBS\centering \cellcolor{\tableheadbgcolor}\textbf{ Rviz map not explored }&\PBS\centering \cellcolor{\tableheadbgcolor}\textbf{ Rviz map explored  }\\\cline{1-2}
\endfirsthead
\hline
\endfoot
\hline
\PBS\centering \cellcolor{\tableheadbgcolor}\textbf{ Rviz map not explored }&\PBS\centering \cellcolor{\tableheadbgcolor}\textbf{ Rviz map explored  }\\\cline{1-2}
\endhead
\PBS\centering  &\PBS\centering   \\\cline{1-2}
\end{longtabu}
\hypertarget{md_README_autotoc_md6}{}\doxysubsection{User-\/\+Interface $<$img src=\char`\"{}https\+://media4.\+giphy.\+com/media/o8\+Q\+Cg\+Jac\+J\+R5balxq8\+Y/200w.\+webp?cid=ecf05e47v2cy2r25cqior5ftits1w4lipka50hjfqkj4jhz4\&rid=200w.\+webp\&ct=s\char`\"{} width=\char`\"{}40\char`\"{}$>$$<$/h2$>$}\label{md_README_autotoc_md6}
This is the primary node, and it was the first to appear.

This node shows the user a little image that explains how to choose the robot\textquotesingle{}s movement modes. It also manages user input by modifying the ros parameters that allow the activation of the nodes defined for each mode if the command is correct.

The following are some of the commands that can be used\+:



Depending on the user input it select the correct action to do, such as running one of the nodes,


\begin{DoxyCode}{0}
\DoxyCodeLine{system(\textcolor{stringliteral}{"rosrun Assignment3\_RT1 achieveGoalPosition"})}
\end{DoxyCode}


close the program (exiting from the main function) or reset the simulation with

\`{}\`{}{\ttfamily cpp ros\+::service\+::call(\char`\"{}/gazebo/reset\+\_\+simulation\char`\"{}, reset)} \`{}\`{}\`{}

For the nodes regarding the movement, which is a dynamic action, I choose to use a {\bfseries{non-\/blocking function}} to get the user input, which is good for speeding up program execution and improving consumer experience (you don\textquotesingle{}t have to press enter key every time). For the node concerning the setting and achievement of the preset coordinates I did not consider it necessary.

The repository I found on Github and changed a little bit for my purposes is from {\ttfamily kb\+Non\+Block} at \href{https://gist.github.com/whyrusleeping/3983293}{\texttt{ teleop\+\_\+twist\+\_\+keyboard\+\_\+repo}}.\hypertarget{md_README_autotoc_md7}{}\doxysubsection{Achieve Goal Position node $<$img src= \char`\"{}https\+://cdn-\/icons-\/png.\+flaticon.\+com/128/854/854894.\+png\char`\"{} width=40$>$}\label{md_README_autotoc_md7}
The first needed feature is implemented by the achieve\+Goal\+Position node. In fact, it gives the robot a new goal based on the user\textquotesingle{}s preferences. This node\textquotesingle{}s goal is to drive the robot into the correct location in the environment once a position coordinates have been specified. At first the user is asked for the goal\textquotesingle{}s x and y coordinates, after which the program generates and publishes a message of type {\ttfamily move\+\_\+base\+\_\+msgs/\+Move\+Base\+Action\+Goal} in the {\ttfamily /move\+\_\+base/goal} topic. The node keeps track of each objective by assigning it an id that is generated at random within the node.

A {\ttfamily /move\+\_\+base/status} message handler is used to determine whether the robot has reached the goal. It examines the messages that have been published on the previously indicated subject.

The initial status code is \textquotesingle{}{\bfseries{1}}\textquotesingle{}, which indicates that the robot is on his way and the goal is active. When the robot comes to a halt, the status code changes to \textquotesingle{}{\bfseries{3}}\textquotesingle{} if the robot has reached the goal position, and to \textquotesingle{}{\bfseries{4}}\textquotesingle{} if the robot is unable to reach the given location. Other statuses that have been managed are for instance the goal lost with status identifier \textquotesingle{}{\bfseries{5}}\textquotesingle{} or the rejected status with the code \textquotesingle{}{\bfseries{9}}\textquotesingle{}.

After having received the feedback of the status and the robot is stopped, so there isn\textquotesingle{}t any active pending goal, the function {\ttfamily Cancel\+Goal()}is called, a message of type {\ttfamily actionlib\+\_\+msgs/\+Goal\+ID} is generated and then published into the {\ttfamily /move\+\_\+base/cancel} topic.\hypertarget{md_README_autotoc_md8}{}\doxysubsection{User Drive Not Assisted node}\label{md_README_autotoc_md8}
The user can control the robot movement with the keypad (remember to click on B\+L\+OC N\+UM, otherwise the correct ascii code will not be read)\+:

\begin{center}\end{center} 

\begin{center}\tabulinesep=1mm
\begin{longtabu}spread 0pt [c]{*{4}{|X[-1]}|}
\hline
\PBS\centering \cellcolor{\tableheadbgcolor}\textbf{ }&\PBS\centering \cellcolor{\tableheadbgcolor}\textbf{ Turn left }&\PBS\centering \cellcolor{\tableheadbgcolor}\textbf{ Do not turn }&\PBS\centering \cellcolor{\tableheadbgcolor}\textbf{ Turn right  }\\\cline{1-4}
\endfirsthead
\hline
\endfoot
\hline
\PBS\centering \cellcolor{\tableheadbgcolor}\textbf{ }&\PBS\centering \cellcolor{\tableheadbgcolor}\textbf{ Turn left }&\PBS\centering \cellcolor{\tableheadbgcolor}\textbf{ Do not turn }&\PBS\centering \cellcolor{\tableheadbgcolor}\textbf{ Turn right  }\\\cline{1-4}
\endhead
\PBS\centering {\bfseries{Go forward}} &\PBS\centering {\ttfamily 7} &\PBS\centering {\ttfamily 8} &\PBS\centering {\ttfamily 9}  \\\cline{1-4}
\PBS\centering {\bfseries{Stop}} &\PBS\centering {\ttfamily 4} &\PBS\centering {\ttfamily 5} &\PBS\centering {\ttfamily 6}  \\\cline{1-4}
\PBS\centering {\bfseries{Go backward}} &\PBS\centering {\ttfamily 1} &\PBS\centering {\ttfamily 2} &\PBS\centering {\ttfamily 3}  \\\cline{1-4}
\end{longtabu}
\end{center} 

\begin{center}\end{center} 

The user can change the robot velocity of 10\% by pressing the following keys\+:

\begin{center}\end{center} 

\begin{center}\tabulinesep=1mm
\begin{longtabu}spread 0pt [c]{*{4}{|X[-1]}|}
\hline
\PBS\centering \cellcolor{\tableheadbgcolor}\textbf{ }&\PBS\centering \cellcolor{\tableheadbgcolor}\textbf{ Linear and Angular }&\PBS\centering \cellcolor{\tableheadbgcolor}\textbf{ Linear only }&\PBS\centering \cellcolor{\tableheadbgcolor}\textbf{ Angular only  }\\\cline{1-4}
\endfirsthead
\hline
\endfoot
\hline
\PBS\centering \cellcolor{\tableheadbgcolor}\textbf{ }&\PBS\centering \cellcolor{\tableheadbgcolor}\textbf{ Linear and Angular }&\PBS\centering \cellcolor{\tableheadbgcolor}\textbf{ Linear only }&\PBS\centering \cellcolor{\tableheadbgcolor}\textbf{ Angular only  }\\\cline{1-4}
\endhead
\PBS\centering {\bfseries{Increment}} &\PBS\centering {\ttfamily $\ast$} &\PBS\centering {\ttfamily +} &\PBS\centering {\ttfamily a}  \\\cline{1-4}
\PBS\centering {\bfseries{Reset}} &\PBS\centering {\ttfamily R or r} &\PBS\centering {\ttfamily e} &\PBS\centering {\ttfamily w}  \\\cline{1-4}
\PBS\centering {\bfseries{Decrease}} &\PBS\centering {\ttfamily /} &\PBS\centering {\ttfamily -\/} &\PBS\centering {\ttfamily z}  \\\cline{1-4}
\end{longtabu}
\end{center} 

\begin{center}\end{center} 

The speed is calculated by multiplying the relative speed by the selected direction, which is an integer between -\/1 and 1. 1 indicates that the robot must go ahead or turn left, -\/1 indicates that the robot must move backward (or turn right), and 0 indicates that the robot must stop.

When the robot starts moving the move\+\_\+base node publishes the right velocity and orientation on the cmd\+\_\+vel topic.\hypertarget{md_README_autotoc_md9}{}\doxysubsection{User Drive Assisted node $<$img src= \char`\"{}https\+://media1.\+giphy.\+com/media/2\+Mn5r\+V\+O\+Q\+S\+Gnl\+Rqu\+Uk\+M/200w.\+webp?cid=ecf05e47wixskor4jhxrjrz9it6ww1p8gd7giv8tq64fke67\&rid=200w.\+webp\&ct=s\char`\"{} width=100 height=60$>$}\label{md_README_autotoc_md9}
Essentially, it intends to allow the user to control the robot in the environment using the keyboard, but we also want to enable automatic obstacle avoidance in this instance.

The node, in particular, reads the same exact user inputs as the user\+Drive\+Not\+Assisted node with non-\/blocking getchar, but it also checks what the robot\textquotesingle{}s laser scanner sees.

This is done~by subscribing to the {\ttfamily /scan} topic and using the message it receives to detect walls that are too close to the robot. This topic is made up of 720 {\itshape ranges}, each of which contains all of the detected distances to the walls on its right, left and front.

Here below the code to select the right action to do in proximity of a wall\+:


\begin{DoxyCode}{0}
\DoxyCodeLine{\textcolor{comment}{// check if the distance of the robot to a wall is less than the threshold set before and update}}
\DoxyCodeLine{\textcolor{comment}{// the speed in such a way that the robot cannot collide with circuit delimitations,}}
\DoxyCodeLine{\textcolor{comment}{// it is able to continue driving avoiding walls.}}
\DoxyCodeLine{\textcolor{keywordflow}{if} (front < th\_min)}
\DoxyCodeLine{\{}
\DoxyCodeLine{        \textcolor{keywordflow}{if} (robot\_vel.linear.x > 0)}
\DoxyCodeLine{        \{}
\DoxyCodeLine{            \textcolor{comment}{// Stop the robot, it can only turn now}}
\DoxyCodeLine{            lin\_dir = 0;}
\DoxyCodeLine{            std::cout << RED << \textcolor{stringliteral}{"Be careful, wall on the front!\(\backslash\)n"}}
\DoxyCodeLine{                      << NC;}
\DoxyCodeLine{        \}}
\DoxyCodeLine{\}}
\DoxyCodeLine{    }
\DoxyCodeLine{\textcolor{keywordflow}{if} (right < th\_min)}
\DoxyCodeLine{\{   }
\DoxyCodeLine{        \textcolor{keywordflow}{if} (robot\_vel.angular.z < 0)}
\DoxyCodeLine{        \{}
\DoxyCodeLine{            \textcolor{comment}{// Stop the twist, it can only go straight now}}
\DoxyCodeLine{            angle\_dir = 0;}
\DoxyCodeLine{            std::cout << RED << \textcolor{stringliteral}{"Be careful, wall on the right!\(\backslash\)n"}}
\DoxyCodeLine{                      << NC;}
\DoxyCodeLine{        \}}
\DoxyCodeLine{\}}
\DoxyCodeLine{    }
\DoxyCodeLine{\textcolor{keywordflow}{if} (left < th\_min)}
\DoxyCodeLine{\{}
\DoxyCodeLine{        \textcolor{keywordflow}{if} (robot\_vel.angular.z > 0)}
\DoxyCodeLine{        \{}
\DoxyCodeLine{            \textcolor{comment}{// Stop the twist, it can only go straight now}}
\DoxyCodeLine{            angle\_dir = 0;}
\DoxyCodeLine{            std::cout << RED << \textcolor{stringliteral}{"Be careful, wall on the left!\(\backslash\)n"}}
\DoxyCodeLine{                      << NC;}
\DoxyCodeLine{        \}}
\DoxyCodeLine{\}}
\end{DoxyCode}


The code examines the minimum distance between two points within these ranges, and if a wall is closer than {\ttfamily th\+\_\+min= 1}, the robot is prevented from approaching it. The robot cannot progress if the front wall is too close, and the robot cannot turn in that direction if one of the barriers on the left or right is too close.

The functions merely edit the linear and angular direction according to the requirements above, setting them to \textquotesingle{}{\bfseries{0}}\textquotesingle{} when required, to activate this security feature.

Finally, the user is prompted with a red risk warning text.

 